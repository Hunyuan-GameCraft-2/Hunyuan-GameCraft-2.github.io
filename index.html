<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Hunyuan-GameCraft-2</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="hero">
      <div class="hero__content">
        <p class="eyebrow">Generative Interactive Game World Modeling</p>
        <h1>Hunyuan-GameCraft-2</h1>
        <p class="subtitle">
          Instruction-driven interactive video generation where Text-Prompt, keyboard, and mouse jointly steer synthetic worlds.
        </p>
        <div class="cta-group">
          <a class="btn primary" href="#abstract">Paper</a>
          <a class="btn secondary" href="#gallery">Video Gallery</a>
        </div>
      </div>
      <div class="hero__stats">
        <div class="stat-card">
          <span class="stat-label">Data Type</span>
          <span class="stat-value">Interactive Video</span>
        </div>
        <div class="stat-card">
          <span class="stat-label">Control Signals</span>
          <span class="stat-value">Prompt + Keyboard + Mouse</span>
        </div>
      </div>
    </header>

    <main>
      <section id="teaser" class="section light teaser-section">
        <div class="section__header">
          <p class="eyebrow">Teaser</p>
          <h2>Instruction-to-Action Playground</h2>
          <p class="teaser-desc">
            Tap any scenario capsule to swap the teaser playback. Each button represents a different interaction rendered by
            Hunyuan-GameCraft-2.
          </p>
        </div>
        <div class="teaser-ring" aria-live="polite">
          <div class="teaser-stage">
            <video
              id="teaserVideo"
              class="teaser-video"
              controls
              playsinline
              poster="asserts/images/teaser.png"
              preload="metadata"
            >
              <source src="asserts/videos/teaser/snowfall.mp4" type="video/mp4" />
              Your browser does not support the video tag.
            </video>
          </div>
          <button
            class="teaser-button group-weather active"
            data-src="asserts/videos/teaser/snowfall.mp4"
            style="--angle: 0deg"
          >
            Snowfall
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/rainfall.mp4"
            style="--angle: 36deg"
          >
            Rainfall
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/lightning.mp4"
            style="--angle: 72deg"
          >
            Lightning Strike
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/explosion.mp4"
            style="--angle: 108deg"
          >
            Trigger an explosion
          </button>
          <button class="teaser-button group-action" data-src="asserts/videos/teaser/gun.mp4" style="--angle: 144deg">
            Hold a gun and fire
          </button>
          <button
            class="teaser-button group-action"
            data-src="asserts/videos/teaser/knife.mp4"
            style="--angle: 180deg"
          >
            Draw a knife
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/man.mp4" style="--angle: 216deg">
            Appear a human
          </button>
          <button
            class="teaser-button group-action"
            data-src="asserts/videos/teaser/phone.mp4"
            style="--angle: 252deg"
          >
            Take out a phone
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/deer.mp4" style="--angle: 288deg">
            Appear a dear
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/car.mp4" style="--angle: 324deg">
            Appear a yellow sport car
          </button>
        </div>
      </section>

      <section id="abstract" class="section">
        <div class="section__header">
          <p class="eyebrow">Abstract</p>
          <h2>Abstract & Key Contributions</h2>
        </div>
        <div class="abstract-layout">
          <article class="abstract-card">
            <h3>Abstract</h3>
            <p>
              Recent advances in generative world models have enabled remarkable progress in creating open-ended game environments, evolving from static scene synthesis toward dynamic, interactive simulation. However, current approaches remain limited by rigid action schemas and high annotation costs, restricting their ability to model diverse in-game interactions and player-driven dynamics.
            </p>
            <p>
              To address these challenges, we introduce <strong>Hunyuan-GameCraft-2</strong>, a new paradigm of instruction-driven interaction for generative game world modeling. Instead of relying on fixed keyboard inputs, our model allows users to control game video contents through natural language prompts, keyboard, or mouse signals, enabling flexible and semantically rich interaction within generated worlds.
            </p>
            <p>
              We formally define the concept of Interactive Video Data and develop an automated pipeline that converts large-scale, unstructured text–video pairs into causally aligned interactive datasets. Built upon a 14B image-to-video Mixture-of-Experts (MoE) foundation model, our model incorporates a text-driven interaction injection mechanism for fine-grained control over camera motion, character behavior, and environment dynamics.
            </p>
            <p>
              Extensive experiments demonstrate that our model generates long-horizon, temporally coherent, and causally grounded interactive game videos that faithfully respond to diverse user instructions such as “open the door,” “draw a torch,” or “trigger an explosion.”
            </p>
          </article>
          <article class="contrib-card">
            <h3>Key Contributions</h3>
            <div class="contrib-list">
              <div class="contrib-item">
                <h4>Unified instruction-driven control</h4>
                <p>
                  We introduce a unified controllable video framework that jointly conditions on free-form text prompts, keyboard inputs,
                  and mouse signals, enabling semantically grounded and causally consistent interaction in game-style environments.
                </p>
              </div>
              <div class="contrib-item">
                <h4>Scalable interactive video data pipeline</h4>
                <p>
                  We formalize interaction in world models and design automated pipelines that transform large-scale, unstructured text–video
                  pairs into open-domain interactive video datasets with implicit causal labels.
                </p>
              </div>
              <div class="contrib-item">
                <h4>Efficient long-horizon interactive generation</h4>
                <p>
                  We distill a bidirectional video generator into a causal autoregressive model, combine randomized image-to-long-video tuning
                  with KV-recache for multi-turn interaction, and integrate engineering optimizations to achieve stable long-horizon generation
                  at real-time 16 FPS.
                </p>
              </div>
              <div class="contrib-item">
                <h4>Comprehensive evaluation and SOTA results</h4>
                <p>
                  Extensive quantitative and qualitative experiments on both general video metrics and interaction-centric evaluations show
                  that our framework sets a new state of the art in generating visually high-quality, temporally coherent videos that reliably
                  follow user instructions.
                </p>
              </div>
            </div>
          </article>
        </div>
      </section>


      <section id="longvideo" class="section section-longvideo">
        <div class="section__header">
          <p class="eyebrow">@longvideo</p>
          <h2>Long Video Generation Gallery</h2>
        </div>
        <div id="longVideoGrid" class="longvideo-grid" aria-live="polite"></div>
      </section>

    </main>

    <footer class="footer">
      <p>© 2025 Hunyuan-GameCraft-2 Team. All rights reserved.</p>
    </footer>
    <script>
      const teaserVideo = document.getElementById("teaserVideo");
      const teaserButtons = document.querySelectorAll(".teaser-button");

      function setTeaserSource(button) {
        const src = button.dataset.src;
        if (!src) return;
        teaserButtons.forEach((btn) => btn.classList.remove("active"));
        button.classList.add("active");
        const shouldAutoplay = !teaserVideo.paused && !teaserVideo.ended;
        const currentTime = teaserVideo.currentTime;
        if (teaserVideo.getAttribute("src") !== src) {
          teaserVideo.pause();
          teaserVideo.setAttribute("src", src);
          teaserVideo.load();
        }
        if (shouldAutoplay || currentTime === 0) {
          teaserVideo.play().catch(() => {});
        }
      }

      teaserButtons.forEach((button) => {
        button.addEventListener("click", () => setTeaserSource(button));
      });

      const longVideoData = [
        {
          id: "prompt-ice-breaker",
          title: "Arcade Siege in a Frozen City",
          prompt: "“Continue the battle as the mech charges through snowstorm streets, dodging collapsing towers while neon HUD text narrates mission updates.”",
          duration: "02:48",
          src: "asserts/videos/longvideo/c6851c79a425f9d79f4704c37cbdb230.mov",
        },
        {
          id: "prompt-cyber-rush",
          title: "Cyberpunk Alley Sprint",
          prompt: "“Pan with the runner as the prompt switches to ‘dash through flickering holo-ads, summon a drone escort, then vault into the traffic layer.’”",
          duration: "01:57",
          src: "asserts/videos/longvideo/95e5cbe99e6b49f44de257d30c411510.mov",
        },
        {
          id: "prompt-dungeon",
          title: "Torchlight Dungeon Expedition",
          prompt: "“Keep the same characters but steer the prose to ‘descend deeper, manifest spectral knights, and rebuild the bridge mid-combat.’”",
          duration: "03:12",
          src: "asserts/videos/longvideo/5a1bbb4acaf9b01626b25f9eddc31642.mov",
        },
        {
          id: "prompt-metropolis",
          title: "Skyrail Metropolis Chase",
          prompt: "“Extend the take with ‘reroute the chase to rooftops, add volumetric rain, and switch to an over-shoulder drone cam.’”",
          duration: "04:05",
          src: "asserts/videos/longvideo/f12706c7eb81aa465308b1a683b20f4e.mov",
        },
        {
          id: "prompt-lab",
          title: "Holographic Lab Build",
          prompt: "“Stream the scene as ‘spawn a fabrication rig, extrude glowing armor plates, then orbit around the finished suit.’”",
          duration: "00:54",
          src: "asserts/videos/longvideo/0a03ad7fe63951633cd61c44452d9bb7.mov",
        },
        {
          id: "prompt-ruins",
          title: "Ancient Ruins Standoff",
          prompt: "“Continue with ‘raise sand cyclones, reveal hidden glyph projectors, then follow the protagonist as they exit into sunrise.’”",
          duration: "02:31",
          src: "asserts/videos/longvideo/baa0feccae276bd421c461cc1f5188a6.mov",
        },
      ];

      const longVideoGrid = document.getElementById("longVideoGrid");
      const LONG_VIDEO_VISIBLE_COUNT = 3;
      let longVideoPointer = 0;
      let longVideoInstance = 0;

      if (longVideoGrid) {
        renderLongVideoGrid();
      }

      function renderLongVideoGrid() {
        if (!longVideoGrid) return;
        longVideoInstance += 1;
        const instanceId = longVideoInstance;
        longVideoGrid.innerHTML = "";

        const visibleCount = Math.min(LONG_VIDEO_VISIBLE_COUNT, longVideoData.length);
        let completed = 0;

        for (let i = 0; i < visibleCount; i += 1) {
          const item = longVideoData[(longVideoPointer + i) % longVideoData.length];
          if (!item) continue;

          const card = document.createElement("div");
          card.className = "longvideo-card";

          const video = document.createElement("video");
          video.controls = true;
          video.playsInline = true;
          video.preload = "metadata";
          video.src = item.src;
          video.autoplay = true;
          video.muted = true;
          video.addEventListener("loadeddata", () => {
            video.play().catch(() => {});
          });
          video.addEventListener(
            "ended",
            () => {
              if (longVideoInstance !== instanceId) return;
              completed += 1;
              if (completed >= visibleCount) {
                rotateLongVideoSet(visibleCount);
              }
            },
            { once: true }
          );

          card.appendChild(video);
          longVideoGrid.appendChild(card);
        }
      }

      function rotateLongVideoSet(step) {
        longVideoPointer = (longVideoPointer + step) % longVideoData.length;
        renderLongVideoGrid();
      }

      /*
      const videoGalleryRoot = document.getElementById("videoGalleryRoot");
      const ACTION_VISIBLE_COUNT = 4;
      const ACTION_ROTATE_MS = 20000;
      const galleryRowState = new Map();

      const videoGalleryData = [
        {
          title: "Environment Change",
          description: "Weather, lighting, and large-scale environmental dynamics.",
          rows: [
            {
              key: "snow",
              label: "Summon snowfall",
              folder: "snow",
              files: ["0003.mp4", "0008.mp4", "0010.mp4", "0011.mp4", "0012.mp4", "0013.mp4", "0042.mp4", "0044.mp4", "0058.mp4", "0088.mp4"],
            },
            {
              key: "rain",
              label: "Call rainfall",
              folder: "rain",
              files: ["0005.mp4", "0013.mp4", "0042.mp4", "0046.mp4", "0055.mp4", "0058.mp4", "0059.mp4", "0065.mp4", "0066.mp4", "0097.mp4"],
            },
            {
              key: "lightning",
              label: "Lightning strike",
              folder: "lightning",
              files: ["0000.mp4", "0005.mp4", "0017.mp4", "0044.mp4", "0046.mp4", "0048.mp4", "0056.mp4", "0091.mp4", "0096.mp4"],
            },
            {
              key: "explosion",
              label: "Trigger an explosion",
              folder: "explosion",
              files: ["0004.mp4", "0013.mp4", "0016.mp4", "0037.mp4", "0048.mp4", "0053.mp4", "0055.mp4", "0065.mp4", "0091.mp4", "0097.mp4"],
            },
          ],
        },
        {
          title: "Actor Actions",
          description: "Character-driven interactions manipulating tools, weapons, or props.",
          rows: [
            {
              key: "torch",
              label: "Light a torch",
              folder: "torch",
              files: ["0001.mp4", "0002.mp4", "0008.mp4", "0013.mp4", "0019.mp4", "0025.mp4", "0031.mp4", "0035.mp4", "0044.mp4", "0047.mp4"],
            },
            {
              key: "opendoor",
              label: "Open the door",
              folder: "opendoor",
              files: ["image_0185.mp4", "image_0983.mp4", "image_3211.mp4", "image_3345.mp4"],
            },
            {
              key: "knife",
              label: "Draw a knife",
              folder: "knife",
              files: ["0000.mp4", "0004.mp4", "0008.mp4", "0009.mp4", "0010.mp4", "0014.mp4", "0018.mp4", "0028.mp4", "0034.mp4", "0036.mp4"],
            },
            {
              key: "gunfire",
              label: "Hold a gun and fire",
              folder: "gunfire",
              files: ["0000.mp4", "0003.mp4", "0005.mp4", "0011.mp4", "0016.mp4", "0018.mp4", "0020.mp4", "0033.mp4", "0038.mp4", "0045.mp4"],
            },
            {
              key: "gun",
              label: "Take out a gun",
              folder: "gun",
              files: ["0002.mp4", "0010.mp4", "0014.mp4", "0017.mp4", "0021.mp4", "0022.mp4", "0023.mp4", "0025.mp4", "0035.mp4", "0037.mp4"],
            },
            {
              key: "phone",
              label: "Take out a phone",
              folder: "phone",
              files: ["0001.mp4", "0003.mp4", "0004.mp4", "0005.mp4", "0014.mp4", "0019.mp4", "0022.mp4", "0028.mp4", "0031.mp4", "0039.mp4"],
            },
          ],
        },
        {
          title: "Entity & Object Appearances",
          description: "Materializing controllable agents, characters, and objects.",
          rows: [
            {
              key: "man",
              label: "Appear a human",
              folder: "man",
              files: ["0001.mp4", "0003.mp4", "0011.mp4", "0012.mp4", "0019.mp4", "0023.mp4", "0027.mp4", "0041.mp4", "0042.mp4", "0043.mp4"],
            },
            {
              key: "car",
              label: "Appear a car",
              folder: "car",
              files: ["0001.mp4", "0007.mp4", "0012.mp4", "0041.mp4", "0047.mp4", "0054.mp4", "0064.mp4", "0073.mp4", "0075.mp4", "0076.mp4"],
            },
            {
              key: "animal",
              label: "Appear a wild animal",
              folder: "animal",
              files: ["0019.mp4", "0028.mp4", "0031.mp4", "0049.mp4", "0050.mp4", "0053.mp4", "0054.mp4", "0058.mp4", "0062.mp4", "0063.mp4"],
            },
          ],
        },
      ];

      function mountVideoGallery() {
        if (!videoGalleryRoot) return;
        videoGalleryRoot.innerHTML = "";
        videoGalleryData.forEach((category) => {
          const categoryEl = document.createElement("section");
          categoryEl.className = "gallery-category";

          const headerEl = document.createElement("div");
          headerEl.className = "gallery-category__header";
          const titleEl = document.createElement("h3");
          titleEl.textContent = category.title;
          const descEl = document.createElement("p");
          descEl.textContent = category.description;
          headerEl.appendChild(titleEl);
          headerEl.appendChild(descEl);
          categoryEl.appendChild(headerEl);

          category.rows.forEach((row) => {
            const rowEl = document.createElement("div");
            rowEl.className = "gallery-action-row";

            const rowTitle = document.createElement("div");
            rowTitle.className = "gallery-action-row__title";
            const h4 = document.createElement("h4");
            h4.textContent = row.label;
            rowTitle.appendChild(h4);
            rowEl.appendChild(rowTitle);

            const videosWrapper = document.createElement("div");
            videosWrapper.className = "gallery-action-row__videos";
            rowEl.appendChild(videosWrapper);

            categoryEl.appendChild(rowEl);
            renderGalleryRow(row, videosWrapper);
          });

          videoGalleryRoot.appendChild(categoryEl);
        });
      }

      function renderGalleryRow(rowConfig, wrapper) {
        const files = rowConfig.files || [];
        if (!files.length) {
          wrapper.innerHTML = '<p class="gallery-empty">Samples coming soon.</p>';
          return;
        }

        const state = galleryRowState.get(rowConfig.key) || { pointer: 0, timer: null, instance: 0 };
        state.instance += 1;
        const instanceId = state.instance;
        wrapper.innerHTML = "";

        const visibleCount = Math.min(ACTION_VISIBLE_COUNT, files.length);
        let completed = 0;

        for (let i = 0; i < visibleCount; i += 1) {
          const file = files[(state.pointer + i) % files.length];
          const card = document.createElement("div");
          card.className = "gallery-video-card";

          const video = document.createElement("video");
          video.src = `asserts/videos/samples/${rowConfig.folder}/${file}`;
          video.muted = true;
          video.controls = true;
          video.playsInline = true;
          video.preload = "metadata";
          video.autoplay = true;
          video.addEventListener("loadeddata", () => {
            video.play().catch(() => {});
          });
          video.addEventListener(
            "ended",
            () => {
              if (galleryRowState.get(rowConfig.key)?.instance !== instanceId) return;
              completed += 1;
              if (completed >= visibleCount) {
                rotateRow();
              }
            },
            { once: true }
          );

          card.appendChild(video);
          wrapper.appendChild(card);
        }

        function rotateRow() {
          if (galleryRowState.get(rowConfig.key)?.instance !== instanceId) return;
          clearTimeout(state.timer);
          state.pointer = (state.pointer + ACTION_VISIBLE_COUNT) % files.length;
          galleryRowState.set(rowConfig.key, state);
          renderGalleryRow(rowConfig, wrapper);
        }

        clearTimeout(state.timer);
        state.timer = setTimeout(() => {
          rotateRow();
        }, ACTION_ROTATE_MS);

        galleryRowState.set(rowConfig.key, state);
      }

      mountVideoGallery();
      */
    </script>
  </body>
</html>

