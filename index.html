<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Hunyuan-GameCraft-2</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="hero">
      <div class="hero__content">
        <p class="eyebrow">Generative Interactive Game World Modeling</p>
        <h1>Hunyuan-GameCraft-2</h1>
        <p class="subtitle">
          Instruction-driven interactive video generation where language, keyboard, and mouse jointly steer synthetic worlds.
        </p>
        <div class="cta-group">
          <a class="btn primary" href="#abstract">Paper</a>
          <a class="btn secondary" href="#gallery">Video Gallery</a>
        </div>
      </div>
      <div class="hero__stats">
        <div class="stat-card">
          <span class="stat-label">Model Size</span>
          <span class="stat-value">14B MoE</span>
        </div>
        <div class="stat-card">
          <span class="stat-label">Data Type</span>
          <span class="stat-value">Interactive Video</span>
        </div>
        <div class="stat-card">
          <span class="stat-label">Control Signals</span>
          <span class="stat-value">Language + Keyboard + Mouse</span>
        </div>
      </div>
    </header>

    <main>
      <section id="teaser" class="section light teaser-section">
        <div class="section__header">
          <p class="eyebrow">Teaser</p>
          <h2>Instruction-to-Action Playground</h2>
          <p class="teaser-desc">
            Tap any scenario capsule to swap the teaser playback. Each button represents a different interaction rendered by
            Hunyuan-GameCraft-2.
          </p>
        </div>
        <div class="teaser-ring" aria-live="polite">
          <div class="teaser-stage">
            <video
              id="teaserVideo"
              class="teaser-video"
              controls
              playsinline
              poster="asserts/images/teaser.png"
              preload="metadata"
            >
              <source src="asserts/videos/teaser/snowfall.mp4" type="video/mp4" />
              Your browser does not support the video tag.
            </video>
          </div>
          <button
            class="teaser-button group-weather active"
            data-src="asserts/videos/teaser/snowfall.mp4"
            style="--angle: 0deg"
          >
            Snowfall
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/rainfall.mp4"
            style="--angle: 36deg"
          >
            Rainfall
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/lightning.mp4"
            style="--angle: 72deg"
          >
            Lightning Strike
          </button>
          <button
            class="teaser-button group-weather"
            data-src="asserts/videos/teaser/explosion.mp4"
            style="--angle: 108deg"
          >
            Trigger an explosion
          </button>
          <button class="teaser-button group-action" data-src="asserts/videos/teaser/gun.mp4" style="--angle: 144deg">
            Hold a gun and fire
          </button>
          <button
            class="teaser-button group-action"
            data-src="asserts/videos/teaser/knife.mp4"
            style="--angle: 180deg"
          >
            Draw a knife
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/man.mp4" style="--angle: 216deg">
            Appear a human
          </button>
          <button
            class="teaser-button group-action"
            data-src="asserts/videos/teaser/phone.mp4"
            style="--angle: 252deg"
          >
            Take out a phone
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/deer.mp4" style="--angle: 288deg">
            Appear a dear
          </button>
          <button class="teaser-button group-entity" data-src="asserts/videos/teaser/car.mp4" style="--angle: 324deg">
            Appear a yellow sport car
          </button>
        </div>
      </section>

      <section id="abstract" class="section">
        <div class="section__header">
          <p class="eyebrow">Abstract</p>
          <h2>Abstract & Key Contributions</h2>
        </div>
        <div class="abstract-layout">
          <article class="abstract-card">
            <h3>Abstract</h3>
            <p>
              Recent advances in generative world models have enabled remarkable progress in creating open-ended game environments, evolving from static scene synthesis toward dynamic, interactive simulation. However, current approaches remain limited by rigid action schemas and high annotation costs, restricting their ability to model diverse in-game interactions and player-driven dynamics.
            </p>
            <p>
              To address these challenges, we introduce <strong>Hunyuan-GameCraft-2</strong>, a new paradigm of instruction-driven interaction for generative game world modeling. Instead of relying on fixed keyboard inputs, our model allows users to control game video contents through natural language prompts, keyboard, or mouse signals, enabling flexible and semantically rich interaction within generated worlds.
            </p>
            <p>
              We formally define the concept of Interactive Video Data and develop an automated pipeline that converts large-scale, unstructured text–video pairs into causally aligned interactive datasets. Built upon a 14B image-to-video Mixture-of-Experts (MoE) foundation model, our model incorporates a text-driven interaction injection mechanism for fine-grained control over camera motion, character behavior, and environment dynamics.
            </p>
            <p>
              Extensive experiments demonstrate that our model generates long-horizon, temporally coherent, and causally grounded interactive game videos that faithfully respond to diverse user instructions such as “open the door,” “draw a torch,” or “trigger an explosion.”
            </p>
          </article>
          <article class="contrib-card">
            <h3>Key Contributions</h3>
            <div class="contrib-list">
              <div class="contrib-item">
                <h4>Instruction-Driven Interaction</h4>
                <p>Multi-modal control channels spanning language, keyboard, and mouse signals for direct semantic mapping to in-game behaviors.</p>
              </div>
              <div class="contrib-item">
                <h4>Interactive Video Data</h4>
                <p>Automated pipeline that extracts causally aligned interaction segments from large-scale text–video pairs, reducing annotation cost.</p>
              </div>
              <div class="contrib-item">
                <h4>Fine-Grained Control</h4>
                <p>Interaction injection module on top of a 14B MoE video generator to separately control camera motion, character actions, and environment dynamics.</p>
              </div>
              <div class="contrib-item">
                <h4>InterBench Benchmark</h4>
                <p>Dedicated benchmark covering action consistency, response latency, scene comprehension, and causal alignment.</p>
              </div>
            </div>
          </article>
        </div>
      </section>

      <section class="section">
        <div class="section__header">
          <p class="eyebrow">Pipeline</p>
          <h2>Interactive Video Data Pipeline</h2>
        </div>
        <div class="pipeline">
          <div class="pipeline-step">
            <span class="step-id">01</span>
            <h3>Multi-source Collection</h3>
            <p>Aggregate large-scale unlabeled text–video pairs and player interaction logs.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">02</span>
            <h3>Causal Alignment</h3>
            <p>Bind instructions to visual feedback using temporal alignment and event extraction.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">03</span>
            <h3>Interaction Annotation</h3>
            <p>Automatically produce triplets of language prompts, input trajectories, and video snippets.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">04</span>
            <h3>Model Adaptation</h3>
            <p>Map control signals into the MoE video generator via the interaction injection module.</p>
          </div>
        </div>
      </section>


      <section class="section video-gallery" id="gallery">
        <div class="section__header">
          <p class="eyebrow">Gallery</p>
          <h2>Action Video Gallery</h2>
        </div>
        <div id="videoGalleryRoot" class="video-gallery__root"></div>
      </section>

    </main>

    <footer class="footer">
      <p>© 2025 Hunyuan-GameCraft-2 Team. All rights reserved.</p>
    </footer>
    <script>
      const teaserVideo = document.getElementById("teaserVideo");
      const teaserButtons = document.querySelectorAll(".teaser-button");

      function setTeaserSource(button) {
        const src = button.dataset.src;
        if (!src) return;
        teaserButtons.forEach((btn) => btn.classList.remove("active"));
        button.classList.add("active");
        const shouldAutoplay = !teaserVideo.paused && !teaserVideo.ended;
        const currentTime = teaserVideo.currentTime;
        if (teaserVideo.getAttribute("src") !== src) {
          teaserVideo.pause();
          teaserVideo.setAttribute("src", src);
          teaserVideo.load();
        }
        if (shouldAutoplay || currentTime === 0) {
          teaserVideo.play().catch(() => {});
        }
      }

      teaserButtons.forEach((button) => {
        button.addEventListener("click", () => setTeaserSource(button));
      });

      const videoGalleryRoot = document.getElementById("videoGalleryRoot");
      const ACTION_VISIBLE_COUNT = 4;
      const ACTION_ROTATE_MS = 20000;
      const galleryRowState = new Map();

      const videoGalleryData = [
        {
          title: "Environment Change",
          description: "Weather, lighting, and large-scale environmental dynamics.",
          rows: [
            {
              key: "snow",
              label: "Summon snowfall",
              folder: "snow",
              files: ["0003.mp4", "0008.mp4", "0010.mp4", "0011.mp4", "0012.mp4", "0013.mp4", "0042.mp4", "0044.mp4", "0058.mp4", "0088.mp4"],
            },
            {
              key: "rain",
              label: "Call rainfall",
              folder: "rain",
              files: ["0005.mp4", "0013.mp4", "0042.mp4", "0046.mp4", "0055.mp4", "0058.mp4", "0059.mp4", "0065.mp4", "0066.mp4", "0097.mp4"],
            },
            {
              key: "lightning",
              label: "Lightning strike",
              folder: "lightning",
              files: ["0000.mp4", "0005.mp4", "0017.mp4", "0044.mp4", "0046.mp4", "0048.mp4", "0056.mp4", "0091.mp4", "0096.mp4"],
            },
            {
              key: "explosion",
              label: "Trigger an explosion",
              folder: "explosion",
              files: ["0004.mp4", "0013.mp4", "0016.mp4", "0037.mp4", "0048.mp4", "0053.mp4", "0055.mp4", "0065.mp4", "0091.mp4", "0097.mp4"],
            },
          ],
        },
        {
          title: "Actor Actions",
          description: "Character-driven interactions manipulating tools, weapons, or props.",
          rows: [
            {
              key: "torch",
              label: "Light a torch",
              folder: "torch",
              files: ["0001.mp4", "0002.mp4", "0008.mp4", "0013.mp4", "0019.mp4", "0025.mp4", "0031.mp4", "0035.mp4", "0044.mp4", "0047.mp4"],
            },
            {
              key: "opendoor",
              label: "Open the door",
              folder: "opendoor",
              files: ["image_0185.mp4", "image_0983.mp4", "image_3211.mp4", "image_3345.mp4"],
            },
            {
              key: "knife",
              label: "Draw a knife",
              folder: "knife",
              files: ["0000.mp4", "0004.mp4", "0008.mp4", "0009.mp4", "0010.mp4", "0014.mp4", "0018.mp4", "0028.mp4", "0034.mp4", "0036.mp4"],
            },
            {
              key: "gunfire",
              label: "Hold a gun and fire",
              folder: "gunfire",
              files: ["0000.mp4", "0003.mp4", "0005.mp4", "0011.mp4", "0016.mp4", "0018.mp4", "0020.mp4", "0033.mp4", "0038.mp4", "0045.mp4"],
            },
            {
              key: "gun",
              label: "Take out a gun",
              folder: "gun",
              files: ["0002.mp4", "0010.mp4", "0014.mp4", "0017.mp4", "0021.mp4", "0022.mp4", "0023.mp4", "0025.mp4", "0035.mp4", "0037.mp4"],
            },
            {
              key: "phone",
              label: "Take out a phone",
              folder: "phone",
              files: ["0001.mp4", "0003.mp4", "0004.mp4", "0005.mp4", "0014.mp4", "0019.mp4", "0022.mp4", "0028.mp4", "0031.mp4", "0039.mp4"],
            },
          ],
        },
        {
          title: "Entity & Object Appearances",
          description: "Materializing controllable agents, characters, and objects.",
          rows: [
            {
              key: "man",
              label: "Appear a human",
              folder: "man",
              files: ["0001.mp4", "0003.mp4", "0011.mp4", "0012.mp4", "0019.mp4", "0023.mp4", "0027.mp4", "0041.mp4", "0042.mp4", "0043.mp4"],
            },
            {
              key: "car",
              label: "Appear a car",
              folder: "car",
              files: ["0001.mp4", "0007.mp4", "0012.mp4", "0041.mp4", "0047.mp4", "0054.mp4", "0064.mp4", "0073.mp4", "0075.mp4", "0076.mp4"],
            },
            {
              key: "animal",
              label: "Appear a wild animal",
              folder: "animal",
              files: ["0019.mp4", "0028.mp4", "0031.mp4", "0049.mp4", "0050.mp4", "0053.mp4", "0054.mp4", "0058.mp4", "0062.mp4", "0063.mp4"],
            },
          ],
        },
      ];

      function mountVideoGallery() {
        if (!videoGalleryRoot) return;
        videoGalleryRoot.innerHTML = "";
        videoGalleryData.forEach((category) => {
          const categoryEl = document.createElement("section");
          categoryEl.className = "gallery-category";

          const headerEl = document.createElement("div");
          headerEl.className = "gallery-category__header";
          const titleEl = document.createElement("h3");
          titleEl.textContent = category.title;
          const descEl = document.createElement("p");
          descEl.textContent = category.description;
          headerEl.appendChild(titleEl);
          headerEl.appendChild(descEl);
          categoryEl.appendChild(headerEl);

          category.rows.forEach((row) => {
            const rowEl = document.createElement("div");
            rowEl.className = "gallery-action-row";

            const rowTitle = document.createElement("div");
            rowTitle.className = "gallery-action-row__title";
            const h4 = document.createElement("h4");
            h4.textContent = row.label;
            rowTitle.appendChild(h4);
            rowEl.appendChild(rowTitle);

            const videosWrapper = document.createElement("div");
            videosWrapper.className = "gallery-action-row__videos";
            rowEl.appendChild(videosWrapper);

            categoryEl.appendChild(rowEl);
            renderGalleryRow(row, videosWrapper);
          });

          videoGalleryRoot.appendChild(categoryEl);
        });
      }

      function renderGalleryRow(rowConfig, wrapper) {
        const files = rowConfig.files || [];
        if (!files.length) {
          wrapper.innerHTML = '<p class="gallery-empty">Samples coming soon.</p>';
          return;
        }

        const state = galleryRowState.get(rowConfig.key) || { pointer: 0, timer: null, instance: 0 };
        state.instance += 1;
        const instanceId = state.instance;
        wrapper.innerHTML = "";

        const visibleCount = Math.min(ACTION_VISIBLE_COUNT, files.length);
        let completed = 0;

        for (let i = 0; i < visibleCount; i += 1) {
          const file = files[(state.pointer + i) % files.length];
          const card = document.createElement("div");
          card.className = "gallery-video-card";

          const video = document.createElement("video");
          video.src = `asserts/videos/samples/${rowConfig.folder}/${file}`;
          video.muted = true;
          video.controls = true;
          video.playsInline = true;
          video.preload = "metadata";
          video.autoplay = true;
          video.addEventListener("loadeddata", () => {
            video.play().catch(() => {});
          });
          video.addEventListener(
            "ended",
            () => {
              if (galleryRowState.get(rowConfig.key)?.instance !== instanceId) return;
              completed += 1;
              if (completed >= visibleCount) {
                rotateRow();
              }
            },
            { once: true }
          );

          card.appendChild(video);
          wrapper.appendChild(card);
        }

        function rotateRow() {
          if (galleryRowState.get(rowConfig.key)?.instance !== instanceId) return;
          clearTimeout(state.timer);
          state.pointer = (state.pointer + ACTION_VISIBLE_COUNT) % files.length;
          galleryRowState.set(rowConfig.key, state);
          renderGalleryRow(rowConfig, wrapper);
        }

        clearTimeout(state.timer);
        state.timer = setTimeout(() => {
          rotateRow();
        }, ACTION_ROTATE_MS);

        galleryRowState.set(rowConfig.key, state);
      }

      mountVideoGallery();
    </script>
  </body>
</html>

