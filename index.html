<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Hunyuan-GameCraft-2</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="hero">
      <div class="hero__content">
        <p class="eyebrow">Generative Interactive Game World Modeling</p>
        <h1>Hunyuan-GameCraft-2</h1>
        <p class="subtitle">
          Instruction-driven interactive video generation where language, keyboard, and mouse jointly steer synthetic worlds.
        </p>
        <div class="cta-group">
          <a class="btn primary" href="#abstract">Paper</a>
          <a class="btn secondary" href="#teaser">Gallery</a>
        </div>
      </div>
      <div class="hero__stats">
        <div class="stat-card">
          <span class="stat-label">Model Size</span>
          <span class="stat-value">14B MoE</span>
        </div>
        <div class="stat-card">
          <span class="stat-label">Data Type</span>
          <span class="stat-value">Interactive Video</span>
        </div>
        <div class="stat-card">
          <span class="stat-label">Control Signals</span>
          <span class="stat-value">Language + Keyboard + Mouse</span>
        </div>
      </div>
    </header>

    <main>
      <section id="teaser" class="section light teaser-section">
        <div class="section__header">
          <p class="eyebrow">Teaser</p>
          <h2>Instruction-to-Action Playground</h2>
          <p class="teaser-desc">
            Tap any scenario capsule to swap the teaser playback. Each button represents a different interaction rendered by
            Hunyuan-GameCraft-2.
          </p>
        </div>
        <div class="teaser-ring" aria-live="polite">
          <div class="teaser-stage">
            <video
              id="teaserVideo"
              class="teaser-video"
              controls
              playsinline
              poster="asserts/images/teaser.png"
              preload="metadata"
            >
              <source src="asserts/videos/teaser/snowfall.mp4" type="video/mp4" />
              Your browser does not support the video tag.
            </video>
          </div>
          <button
            class="teaser-button active"
            data-src="asserts/videos/teaser/snowfall.mp4"
            style="--angle: 0deg"
          >
            Snowfall
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/rainfall.mp4" style="--angle: 36deg">
            Rainfall
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/lightning.mp4" style="--angle: 72deg">
            Lightning
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/explosion.mp4" style="--angle: 108deg">
            Explosion
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/gun.mp4" style="--angle: 144deg">
            Gunfire
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/knife.mp4" style="--angle: 180deg">
            Blade
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/man.mp4" style="--angle: 216deg">
            Wanderer
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/phone.mp4" style="--angle: 252deg">
            Signal
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/deer.mp4" style="--angle: 288deg">
            Forest
          </button>
          <button class="teaser-button" data-src="asserts/videos/teaser/car.mp4" style="--angle: 324deg">
            Pursuit
          </button>
        </div>
      </section>

      <section id="abstract" class="section">
        <div class="section__header">
          <p class="eyebrow">Abstract</p>
          <h2>Introduction & Abstract</h2>
        </div>
        <div class="abstract-grid">
          <article class="abstract-card">
            <h3>Overview Abstract</h3>
            <p>
              Generative world models are rapidly evolving from static scene synthesis toward dynamic and interactive game environments. Existing approaches, however, still struggle with rigid action templates and costly annotations, limiting their coverage of diverse player interactions. We therefore present
              <strong>Hunyuan-GameCraft-2</strong>, a paradigm centered on instruction-driven interaction where natural language prompts, keyboard, and mouse signals jointly control generated videos.
            </p>
            <p>
              We formally define Interactive Video Data and construct an automated pipeline that converts massive text–video pairs into causally aligned interactive datasets. Built on a 14B image-to-video MoE foundation, our text-driven interaction injection mechanism provides fine control over camera motion, character behaviors, and environment dynamics, while the InterBench benchmark evaluates interaction fidelity. Experiments show that the model produces long-horizon, causally grounded videos responding reliably to commands such as “open the door,” “draw a torch,” and “trigger an explosion.”
            </p>
          </article>
          <article class="abstract-card">
            <h3>English Abstract</h3>
            <p>
              Recent advances in generative world models have enabled remarkable progress in creating open-ended game environments, evolving from static scene synthesis toward dynamic, interactive simulation. However, current approaches remain limited by rigid action schemas and high annotation costs, restricting their ability to model diverse in-game interactions and player-driven dynamics.
            </p>
            <p>
              To address these challenges, we introduce <strong>Hunyuan-GameCraft-2</strong>, a new paradigm of instruction-driven interaction for generative game world modeling. Instead of relying on fixed keyboard inputs, our model allows users to control game video contents through natural language prompts, keyboard, or mouse signals, enabling flexible and semantically rich interaction within generated worlds.
            </p>
            <p>
              We formally define the concept of Interactive Video Data and develop an automated pipeline that converts large-scale, unstructured text–video pairs into causally aligned interactive datasets. Built upon a 14B image-to-video Mixture-of-Experts (MoE) foundation model, our model incorporates a text-driven interaction injection mechanism for fine-grained control over camera motion, character behavior, and environment dynamics. We introduce an interaction-focused benchmark, InterBench to evaluate interaction performance comprehensively.
            </p>
            <p>
              Extensive experiments demonstrate that our model generates long-horizon, temporally coherent, and causally grounded interactive game videos that faithfully respond to diverse user instructions such as “open the door,” “draw a torch,” or “trigger an explosion.”
            </p>
          </article>
        </div>
      </section>

      <section class="section light">
        <div class="section__header">
          <p class="eyebrow">Highlights</p>
          <h2>Key Contributions</h2>
        </div>
        <div class="card-grid">
          <article class="card">
            <h3>Instruction-Driven Interaction</h3>
            <p>
              Multi-modal control channels spanning language, keyboard, and mouse signals for direct semantic mapping to in-game behaviors.
            </p>
          </article>
          <article class="card">
            <h3>Interactive Video Data</h3>
            <p>
              Automated pipeline that extracts causally aligned interaction segments from large-scale text–video pairs, reducing annotation cost.
            </p>
          </article>
          <article class="card">
            <h3>Fine-Grained Control</h3>
            <p>
              Interaction injection module on top of a 14B MoE video generator to separately control camera motion, character actions, and environment dynamics.
            </p>
          </article>
          <article class="card">
            <h3>InterBench Benchmark</h3>
            <p>
              Dedicated benchmark covering action consistency, response latency, scene comprehension, and causal alignment.
            </p>
          </article>
        </div>
      </section>

      <section class="section">
        <div class="section__header">
          <p class="eyebrow">Pipeline</p>
          <h2>Interactive Video Data Pipeline</h2>
        </div>
        <div class="pipeline">
          <div class="pipeline-step">
            <span class="step-id">01</span>
            <h3>Multi-source Collection</h3>
            <p>Aggregate large-scale unlabeled text–video pairs and player interaction logs.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">02</span>
            <h3>Causal Alignment</h3>
            <p>Bind instructions to visual feedback using temporal alignment and event extraction.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">03</span>
            <h3>Interaction Annotation</h3>
            <p>Automatically produce triplets of language prompts, input trajectories, and video snippets.</p>
          </div>
          <div class="pipeline-step">
            <span class="step-id">04</span>
            <h3>Model Adaptation</h3>
            <p>Map control signals into the MoE video generator via the interaction injection module.</p>
          </div>
        </div>
      </section>

      <section class="section light">
        <div class="section__header">
          <p class="eyebrow">Benchmark</p>
          <h2>InterBench Evaluation</h2>
        </div>
        <div class="benchmark">
          <div>
            <h3>Metric Coverage</h3>
            <ul>
              <li>Interaction response: latency and accuracy of visual feedback</li>
              <li>Action consistency: stability of target behaviors</li>
              <li>Spatiotemporal coherence: long-horizon perceptual consistency</li>
              <li>Causal alignment: logical faithfulness to user instructions</li>
            </ul>
          </div>
          <div class="benchmark-card">
            <p class="metric-label">Average Response Score</p>
            <p class="metric-value">91.3</p>
            <p class="metric-desc">Outperforms leading baselines across multitask prompts</p>
          </div>
        </div>
      </section>

      <section class="section">
        <div class="section__header">
          <p class="eyebrow">Results</p>
          <h2>Interaction Examples</h2>
        </div>
        <div class="results-grid">
          <figure class="result-card">
            <div class="result-thumb">Open the door</div>
            <figcaption>Character executes a natural-language door command with automatic camera push-in.</figcaption>
          </figure>
          <figure class="result-card">
            <div class="result-thumb">Draw a torch</div>
            <figcaption>Gesture-controlled torch creation that relights the scene with dynamic illumination.</figcaption>
          </figure>
          <figure class="result-card">
            <div class="result-thumb">Trigger an explosion</div>
            <figcaption>Combined keyboard–mouse input triggers an explosion with particle debris.</figcaption>
          </figure>
        </div>
      </section>

    </main>

    <footer class="footer">
      <p>© 2025 Hunyuan-GameCraft-2 Team. All rights reserved.</p>
    </footer>
    <script>
      const teaserVideo = document.getElementById("teaserVideo");
      const teaserButtons = document.querySelectorAll(".teaser-button");

      function setTeaserSource(button) {
        const src = button.dataset.src;
        if (!src) return;
        teaserButtons.forEach((btn) => btn.classList.remove("active"));
        button.classList.add("active");
        const shouldAutoplay = !teaserVideo.paused && !teaserVideo.ended;
        const currentTime = teaserVideo.currentTime;
        if (teaserVideo.getAttribute("src") !== src) {
          teaserVideo.pause();
          teaserVideo.setAttribute("src", src);
          teaserVideo.load();
        }
        if (shouldAutoplay || currentTime === 0) {
          teaserVideo.play().catch(() => {});
        }
      }

      teaserButtons.forEach((button) => {
        button.addEventListener("click", () => setTeaserSource(button));
      });
    </script>
  </body>
</html>

